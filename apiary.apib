FORMAT: 1A
# Periscope

![SequenceIQ](https://raw.githubusercontent.com/sequenceiq/sequenceiq.github.io/master/img/logo.png)

*Periscope is a powerful, fast, thick and top-to-bottom right-hander, eastward from Sumbawa's famous west-coast. Timing is critical, as needs a number of elements to align before it shows its true colors.*

*Periscope brings QoS and autoscaling to Hadoop YARN. Built on cloud resource management and YARN schedulers, allows to associate SLA policies to applications.*

##Overview

The purpose of Periscope is to bring QoS and autoscaling to a multi-tenant Hadoop YARN cluster, while allowing to apply SLA policies to individual applications.
At [SequenceIQ](http://sequenceiq.com) working with multi-tenant Hadoop clusters for quite a while, we have always seen the same frustration and fight for resource between users.
The **FairScheduler** was partially solving this problem - bringing in fairness based on the notion of [Dominant Resource Fairness](http://static.usenix.org/event/nsdi11/tech/full_papers/Ghodsi.pdf).
With the emergence of Hadoop 2 YARN and the **CapacityScheduler** we had the option to maximize throughput and utilization for a multi-tenant cluster in an operator-friendly manner.
The scheduler works around the concept of queues. These queues are typically setup by administrators to reflect the economics of the shared cluster.
While this is a pretty good abstraction and brings some level of SLA for predictable workloads, it often needs proper design ahead.
The queue hierarchy and resource allocation needs to be changed when new tenants and workloads are moved to the cluster.

Periscope was designed around the idea of `autoscaling` clusters - without any need to preconfigure queues, cluster nodes or apply capacity planning ahead.

##How it works

Periscope monitors the application progress, the number of YARN containers/resources and their allocation, queue depths, the number of available cluster nodes and their health. 
Since we have switched to YARN a while ago (been among the first adopters) we have run an open source [monitoring project](https://github.com/sequenceiq/yarn-monitoring), based on R.
We have been collecting metrics from the YARN Timeline server, Hadoop Metrics2 and Ambari's Nagios/Ganglia - and profiling the applications and correlating with these metrics.
One of the key findings was that while low level metrics are good to understand the cluster health - they might not necessarily help on making decisions when applying different SLA policies on a multi-tenant cluster. 
Focusing on higher level building blocks as queue depth, YARN containers, etc actually brings in the same quality of service, while not being lost in low level details.

Periscope works with two types of Hadoop clusters: `static` and `dynamic`. Periscope does not require any pre-installation - the only thing it requires is to be `attached` to an Ambari server's REST API.

##Clusters

### Static clusters
From Periscope point of view we consider a cluster `static` when the cluster capacity can't be increased horizontally.
This means that the hardware resources are already given - and the throughput can't be increased by adding new nodes.
Periscope introspects the job submission process, monitors the applications and applies the following SLAs:

  1. Application ordering - can guarantee that a higher priority application finishes before another one (supporting parallel or sequential execution)
  2. Moves running applications between priority queues
  3. *Attempts* to enforce time based SLA (execution time, finish by, finish between, recurring)
  4. *Attempts* to enforce guaranteed cluster capacity requests ( x % of the resources)
  5. Support for distributed (but not YARN ready) applications using Apache Slider
  6. Attach priorities to SLAs
  
_Note: not all of the features above are supported in the first `public beta` version. There are dependencies we contributed to Hadoop, YARN and Ambari and they will be included in the next releases (2.6 and 1.7)_


### Autoscaling clusters
From Periscope point of view we consider a cluster `dynamic` when the cluster capacity can be increased horizontally.
This means that nodes can be added or removed on the fly - thus the cluster’s throughput can be increased or decreased based on the cluster load and scheduled applications.
Periscope works with [Cloudbreak](http://sequenceiq.com/cloudbreak/) to add or remove nodes from the cluster based on the SLA policies and thus continuously provide a high *quality of service* for the multi-tenand Hadoop cluster.
Just to refresh memories - [Cloudbreak](http://sequenceiq.com/products.html) is [SequenceIQ's](http://sequenceiq.com) open source, cloud agnostic Hadoop as a Service API.
Given the option of provisioning or decommissioning cluster nodes on the fly, Periscope allows you to use the following set of SLAs:

  1. Application ordering - can guarantee that a higher priority application finishes before another one (supporting parallel or sequential execution)
  2. Moves running applications between priority queues
  3. *Enforce* time based SLA (execution time, finish by, finish between, recurring) by increasing cluster capacity and throughput
  4. Smart decommissioning - avoids HDFS storms, keeps `paid` nodes alive till the last minute
  5. *Enforce* guaranteed cluster capacity requests ( x % of the resources)
  6. *Private* cluster requests - supports provisioning of short lived private clusters with the possibility to merge them.
  7. Support for distributed (but not YARN ready) applications using Apache Slider
  8. Attach priorities to SLAs

_Note: not all of the features above are supported in the first `public beta` version. There are dependencies we contributed to Hadoop, YARN and Ambari and they will be included in the next releases (2.6 and 1.7)_

#Group Clusters
A Hadoop cluster is a set of components and services launched in order to store, analyze and process unstructured data. 
Periscope can work with any Hadoop 2/ YARN cluster provisioned with Apache Ambari, and supports any YARN application.

##Add [/clusters]
###Add a cluster [POST]
Add a Hadoop cluster to be monitored by Periscope. Note that Periscope does not require any pre-installation of components on cluster nodes. 
To link a Hadoop cluster with Periscope the only required this is the Apache Ambari REST API endpoint.

+ Request (application/json)

        {
            "host": "172.24.0.2",
            "port": "8080",
            "user": "admin",
            "pass": "admin"
        }

+ Response 201 (application/json)

        {
            "appMovement": "allowed",
            "state": "RUNNING",
            "port": "8080",
            "host": "172.24.0.2",
            "id": "1"
        }

##Get [/clusters/{id}]
###Retrieve cluster information [GET]

+ Parameters
    + id (required String `id`) ... The id of the cluster.

+ Request

        {

        }

+ Response 200 (application/json)

        {
            "appMovement": "allowed",
            "state": "RUNNING",
            "port": "8080",
            "host": "172.24.0.2",
            "id": "1"
        }

##Remove [/clusters/{id}]
###Remove a cluster [DELETE]

+ Parameters
    + id (required String `id`) ... The id of the cluster.

+ Request

        {

        }

+ Response 200 (application/json)

        {
            "appMovement": "allowed",
            "state": "RUNNING",
            "port": "8080",
            "host": "172.24.0.2",
            "id": "1"
        }

##List [/clusters]
###List all cluster information [GET]

+ Request

        {

        }

+ Response 200 (application/json)

        [
          {
            "appMovement": "allowed",
            "state": "RUNNING",
            "port": "8080",
            "host": "172.24.0.2",
            "id": "1"
          }
        ]
        

##State [/clusters/{clusterId}/state]
###Set state [POST]

+ Parameters
    + clusterId (required String `clusterID`) ... The id of the cluster.

+ Request (application/json)

        {
          "state": "SUSPENDED"
        }

+  Response 200 (application/json)

        {
            "appMovement": "prohibited",
            "state": "SUSPENDED",
            "port": "8080",
            "host": "172.24.0.2",
            "id": "1"
        }

##Movements [/clusters/{clusterId}/movement]
###Configure application movements [POST]
Configure whether moveing the submitted applications between different queues to set a priority among them is allowed or not. 
Based on our contribution to the CapacityScheduler [YARN-2248](https://issues.apache.org/jira/browse/YARN-2248) we made available to move running applications between queues.

+ Parameters
    + clusterId (required String `clusterID`) ... The id of the cluster.

+ Request (application/json)

        {
          "allowed": "false" 
        }

+  Response 200 (application/json)

        {
            "appMovement": "prohibited",
            "state": "SUSPENDED",
            "port": "8080",
            "host": "172.24.0.2",
            "id": "1"
        }

#Group Alarms
An alarm watches a `metric` over a specified time period, and used by one or more action or scaling policy based on the value of the metric relative to a given threshold over a number of time periods. In case Periscope raises an alarm an action (e.g. sending an email) or a scaling policy is triggered. Alarms are based on metrics. The current supported `metrics` are: 
*`PENDING_CONTAINERS`- pending YARN containers

*`PENDING_APPLICATIONS` - pending/queued YARN applications

*`LOST_NODES` - cluster nodes lost

*`UNHEALTHY_NODES` - unhealthy cluster nodes

*`GLOBAL_RESOURCES` - global resources 

Measured `metrics` are compared with pre-configured values using operators. The `comparison operators` are: `LESS_THAN`, `GREATER_THAN`, `LESS_OR_EQUAL_THAN`, `GREATER_OR_EQUAL_THAN`, `EQUALS`.
In order to avoid reacting for sudden spikes in the system and apply policies only in case of a sustained system stress, `alarms` have to be sustained over a `period` of time.  The `period` specifies the time period in minutes during the alarm has to be sustained. 

Also a `threshold` can be configured, which specifies the variance applied by the operator for the selected `metric`.


##Add, remove and show [/clusters/{clusterId}/alarms]
###Set the alarms [POST]

+ Parameters
    + clusterId (required String `clusterID`) ... The id of the cluster.

+ Request (application/json)

        {
          "alarms": [
            {
              "alarmName": "pendingContainerHigh",
              "description": "Number of pending containers is high",
              "metric": "PENDING_CONTAINERS",
              "threshold": 10,
              "comparisonOperator": "GREATER_THAN",
              "period": 10
            },
            {
              "alarmName": "freeGlobalResourcesRateLow",
              "description": "Low free global resource rate",
              "metric": "GLOBAL_RESOURCES",
              "threshold": 1,
              "comparisonOperator": "EQUALS",
              "period": 10,
              "notifications": [
                {
                  "target": [
                    "some1@gmail.com",
                    "other1@gmail.com"
                  ],
                  "notificationType": "EMAIL"
                }
              ]
            }
          ]
        }

+ Response 201 (application/json)

        {
          "alarms": [
            {
              "notifications": [],
              "id": 102,
              "alarmName": "pendingContainerHigh",
              "description": "Number of pending containers is high",
              "metric": "PENDING_CONTAINERS",
              "threshold": 10,
              "comparisonOperator": "GREATER_THAN",
              "period": 1,
              "scalingPolicyId": null
            },
            {
              "notifications": [
                {
                  "notificationType": "EMAIL",
                  "target": [
                    "some1@gmail.com",
                    "other1@gmail.com"
                  ]
                }
              ],
              "id": 103,
              "alarmName": "freeGlobalResourcesRateLow",
              "description": "Low free global resource rate",
              "metric": "GLOBAL_RESOURCES",
              "threshold": 1,
              "comparisonOperator": "EQUALS",
              "period": 1,
              "scalingPolicyId": null
            }
          ]
        }

###Add new alarm [PUT]

+ Parameters
    + clusterId (required String `clusterID`) ... The id of the cluster.

+ Request (application/json)

        {
          "alarmName": "unhealthyNodesHigh",
          "description": "Number of unhealthy nodes is high",
          "metric": "UNHEALTHY_NODES",
          "threshold": 5,
          "comparisonOperator": "GREATER_OR_EQUAL_THAN",
          "period": 5
        }

+ Response 201 (application/json)

        {
          "alarms": [
            {
              "notifications": [],
              "id": 100,
              "alarmName": "pendingContainerHigh",
              "description": "Number of pending containers is high",
              "metric": "PENDING_CONTAINERS",
              "threshold": 10,
              "comparisonOperator": "GREATER_THAN",
              "period": 1,
              "scalingPolicyId": null
            },
            {
              "notifications": [
                {
                  "notificationType": "EMAIL",
                  "target": [
                    "some1@gmail.com"
                  ]
                }
              ],
              "id": 101,
              "alarmName": "freeGlobalResourcesRateLow",
              "description": "Low free global resource rate",
              "metric": "GLOBAL_RESOURCES",
              "threshold": 1,
              "comparisonOperator": "EQUALS",
              "period": 1,
              "scalingPolicyId": null
            },
            {
              "notifications": [],
              "id": 102,
              "alarmName": "unhealthyNodesHigh",
              "description": "Number of unhealthy nodes is high",
              "metric": "UNHEALTHY_NODES",
              "threshold": 5,
              "comparisonOperator": "GREATER_OR_EQUAL_THAN",
              "period": 5,
              "scalingPolicyId": null
            }
          ]
        }

###Retrieve configured alarms [GET]

+ Parameters
    + clusterId (required String `clusterID`) ... The id of the cluster.

+ Request (application/json)

        {

        }

+ Response 200 (application/json)

        {
          "alarms": [
            {
              "notifications": [],
              "scalingPolicyId": null,
              "period": 10,
              "comparisonOperator": "GREATER_THAN",
              "threshold": 10,
              "metric": "PENDING_CONTAINERS",
              "description": "Number of pending containers is high",
              "alarmName": "pendingContainerHigh",
              "id": 50
            },
            {
              "notifications": [],
              "scalingPolicyId": null,
              "period": 10,
              "comparisonOperator": "EQUALS",
              "threshold": 1,
              "metric": "GLOBAL_RESOURCES",
              "description": "Low free global resource rate",
              "alarmName": "freeGlobalResourcesRateLow",
              "id": 51
            }
          ]
        }

##Delete [/clusters/{clusterId}/alarms/{alarmId}]
###Delete an alarm [DELETE]

+ Parameters
    + clusterId (required String `clusterID`) ... The id of the cluster.
    + alarmId (required String `alarmId`) ... The id of the alarm.

+ Request (application/json)
        
        {

        }

+ Response 200 (application/json)

        {
          "alarms": [
            {
              "notifications": [],
              "scalingPolicyId": null,
              "period": 10,
              "comparisonOperator": "EQUALS",
              "threshold": 1,
              "metric": "GLOBAL_RESOURCES",
              "description": "Low free global resource rate",
              "alarmName": "freeGlobalResourcesRateLow",
              "id": 51
            }
          ]
        }

#Group Scaling Policy
Scaling is the ability to increase or decrease the capacity of the Hadoop cluster or application. 
When scaling policies are used, the capacity is automatically increased or decreased according to the conditions defined.
Periscope will do the heavy lifting and based on the alarms and the scaling policy linked to them it executes the associated policy.
By default a fully configured and running [Cloudbreak](https://cloudbreak.sequenceiq.com/) cluster contains no SLA policies. 
An SLA scaling policy can contain multiple alarms. As an alarm is triggered a `scalingAdjustment` is applied, however to keep the cluster size within boundaries a `minSize` and `maxSize` is attached to the cluster - thus a scaling policy can never over or undersize a cluster. Also in order to avoid stressing the cluster we have introduced a `cooldown` period (minutes) - though an alarm is raised and there is an associated scaling policy, the system will not apply the policy within the configured timeframe. In an SLA scaling policy the triggered rules are applied in order.
Hosts can be added or removed from specific `hostgroups` - Ambari host groups are a set of machines with the same Hadoop “components” installed.

##Add, remove and show [/clusters/{clusterId}/policies]
###Set the scaling policies. [POST]

+ Parameters
    + clusterId (required String `clusterID`) ... The id of the cluster.

+ Request (application/json)

        {
          "minSize": 2,
          "maxSize": 10,
          "cooldown": 35,
          "scalingPolicies": [
            {
              "name": "downScaleWhenHighResource",
              "adjustmentType": "NODE_COUNT",
              "scalingAdjustment": -2,
              "hostGroup": "slave_1",
              "alarmId": "51"
            },
            {
              "name": "upScaleWhenHighPendingContainers",
              "adjustmentType": "PERCENTAGE",
              "scalingAdjustment": 40,
              "hostGroup": "slave_1",
              "alarmId": "50"
            }
          ]
        }

+ Response 201 (application/json)

        {
          "cooldown": 35,
          "scalingPolicies": [
            {
              "alarmId": 50,
              "scalingAdjustment": 40,
              "hostGroup": "slave_1",
              "adjustmentType": "PERCENTAGE",
              "name": "upScaleWhenHighPendingContainers",
              "id": 101
            },
            {
              "alarmId": 51,
              "scalingAdjustment": -2,
              "hostGroup": "slave_1",
              "adjustmentType": "NODE_COUNT",
              "name": "downScaleWhenHighResource",
              "id": 100
            }
          ],
          "maxSize": 10,
          "minSize": 2
        }

###Add a scaling policy. [PUT]

+ Parameters
    + clusterId (required String `clusterID`) ... The id of the cluster.

+ Request (application/json)

        {
          "name": "upScaleWhenHighUnhealthyNodes",
          "adjustmentType": "NODE_COUNT",
          "scalingAdjustment": 5,
          "hostGroup": "slave_1",
          "alarmId": "102"
        }

+ Response 201 (application/json)

        {
          "cooldown": 1,
          "scalingPolicies": [
            {
              "hostGroup": "slave_1",
              "alarmId": 100,
              "scalingAdjustment": 40,
              "adjustmentType": "PERCENTAGE",
              "name": "upScaleWhenHighPendingContainers",
              "id": 200
            },
            {
              "hostGroup": "slave_1",
              "alarmId": 101,
              "scalingAdjustment": -2,
              "adjustmentType": "NODE_COUNT",
              "name": "downScaleWhenHighResource",
              "id": 201
            },
            {
              "hostGroup": "slave_1",
              "alarmId": 102,
              "scalingAdjustment": 5,
              "adjustmentType": "NODE_COUNT",
              "name": "upScaleWhenHighUnhealthyNodes",
              "id": 202
            }
          ],
          "maxSize": 10,
          "minSize": 2
        }

###List the scaling policies. [GET]

+ Parameters
    + clusterId (required String `clusterID`) ... The id of the cluster.

+ Request (application/json)

        {

        }

+ Response 200 (application/json)

        {
          "cooldown": 35,
          "scalingPolicies": [
            {
              "alarmId": 50,
              "scalingAdjustment": 40,
              "hostGroup": "slave_1",
              "adjustmentType": "PERCENTAGE",
              "name": "upScaleWhenHighPendingContainers",
              "id": 101
            },
            {
              "alarmId": 51,
              "scalingAdjustment": -2,
              "hostGroup": "slave_1",
              "adjustmentType": "NODE_COUNT",
              "name": "downScaleWhenHighResource",
              "id": 100
            }
          ],
          "maxSize": 10,
          "minSize": 2
        }

##Delete [/clusters/{clusterId}/policies/{policyId}]
###Delete a scaling policy. [DELETE]

+ Parameters
    + clusterId (required String `clusterID`) ... The id of the cluster.
    + policyId (required String `policyId`) ... The id of the policy.

+ Request (application/json)

        {

        }

+ Response 200 (application/json)

        {
          "cooldown": 35,
          "scalingPolicies": [
            {
              "alarmId": 50,
              "scalingAdjustment": 40,
              "hostGroup": "slave_1",
              "adjustmentType": "PERCENTAGE",
              "name": "upScaleWhenHighPendingContainers",
              "id": 101
            }
          ],
          "maxSize": 10,
          "minSize": 2
        }

#Group Applications
A Hadoop YARN application is a packaged workload submitted to a cluster. An application requests resources from YARN Resource Manager. The resources are allocated as YARN containers. By default Periscope works with the Hadoop YARN Capacity Scheduler. Using the Capacity Scheduler applications are submitted in different priority queues. The queue configurations, their depth, associated resources, etc have to be designed ahead - and adapted in case of new tenants, applications or workloads are using the cluster.
At SequenceIQ, through our contributions to Apache YARN we facilitate moving applications between queues - and thus use the SLA policies attached to these queues. Even more, those SLA policies which were previously attached to Capacity Scheduler queues now can be attached to submitted jobs/applications. 
Also we facilitate changing the resources allocated to a running application - even though they were submitted and already running. 
_Note: not all of the features above are supported in the first `public beta` version. There are dependencies we contributed to Hadoop, Ambari and YARN and they will be included in the next releases (1.7 and 2.6)_

##List [/clusters/{clusterId}/applications]
###List running applications and their resources [GET]

+ Parameters
    + clusterId (required String `clusterID`) ... The id of the cluster.

+ Request (application/json)

        {

        }

+ Response 200 (application/json)

        [
            {
                "usedVCores": 1,
                "usedMemory": 512,
                "reservedContainers": 0,
                "usedContainers": 1,
                "appId": "application_1407836063840_0001",
                "user": "hdfs",
                "queue": "default",
                "state": "ACCEPTED",
                "url": "http://amb0.mycorp.kom:8088/proxy/application_1407836063840_0001/",
                "start": 1407847270776,
                "finish": 0,
                "progress": 0
              }
        ]

#Group Configuration
Periscope brings in the capability to reconfigure a running cluster - in particular resource properties heavily used. 
These properties currently are mostly related to the Capacity Scheduler configurations, but as we add functionality to Periscope this set of properties will constantly increase.

##Update [/clusters/{clusterId}/configurations]
###Reload Hadoop YARN configuration [POST]

+ Parameters
    + clusterId (required String `clusterID`) ... The id of the cluster.

+ Request (application/json)

        {

        }

+ Response 200 (application/json)

        {
            "appMovement": "allowed",
            "state": "RUNNING",
            "port": "8080",
            "host": "172.24.0.2",
            "id": "1"
        }

##Queue setup [/clusters/{clusterId}/configurations/queue]
###Reconfigure the queue capacities [POST]

+ Parameters
    + clusterId (required String `clusterID`) ... The id of the cluster.

+ Request (application/json)

        {
          "setup": [
            {
              "name": "default",
              "capacity": 55
            },
            {
              "name": "high",
              "capacity": 45
            }
          ]
        }

+ Response 200 (application/json)

        {
          "properties": {
            "yarn.scheduler.capacity.root.capacity": "100",
            "yarn.scheduler.capacity.root.high.maximum-capacity": "45",
            "yarn.scheduler.capacity.root.default.user-limit-factor": "1",
            "yarn.scheduler.capacity.root.high.user-limit-factor": "1",
            "yarn.scheduler.capacity.root.default.acl_submit_applications": "*",
            "yarn.scheduler.capacity.maximum-am-resource-percent": "0.2",
            "yarn.scheduler.capacity.root.high.state": "RUNNING",
            "yarn.scheduler.capacity.root.default.maximum-capacity": "55",
            "yarn.scheduler.capacity.node-locality-delay": "40",
            "yarn.scheduler.capacity.root.default.acl_administer_jobs": "*",
            "yarn.scheduler.capacity.root.queues": "default,high",
            "yarn.scheduler.capacity.root.default.state": "RUNNING",
            "yarn.scheduler.capacity.root.unfunded.capacity": "50",
            "yarn.scheduler.capacity.root.high.acl_administer_jobs": "*",
            "yarn.scheduler.capacity.root.acl_administer_queue": "*",
            "yarn.scheduler.capacity.root.high.acl_submit_applications": "*",
            "yarn.scheduler.capacity.root.high.capacity": "45",
            "yarn.scheduler.capacity.maximum-applications": "9999",
            "yarn.scheduler.capacity.root.default.capacity": "55"
          },
          "setup": [
            {
              "capacity": 55,
              "name": "default"
            },
            {
              "capacity": 45,
              "name": "high"
            }
          ]
        }
